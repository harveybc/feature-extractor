# REFERENCE - System Functionality

## 1. System Overview

The **Synthetic Data Generator (SDG)** is a sophisticated plugin-based framework implementing a Sequential Conditional Variational Autoencoder–Generative Adversarial Network (SC-VAE-GAN). It is designed for generating high-quality, multi-feature time series data, with a strong emphasis on modularity, maintainability, testability, and extensibility.

### Key Functional Highlights:

*   **23-Feature Training Architecture**: 
    *   **Training Mode**: GAN trains using only 23 core base features (generator outputs 23, discriminator expects 23)
    *   **Generate Mode**: Generates 23 base features, then post-processes to add technical indicators + seasonal features + sub-periodicity ticks
    *   **Base Features**: OHLC prices, market indicators (VIX, S&P500), bid/ask spreads, sub-periodicity ticks
    *   **Post-processing**: 15 technical indicators + 16 interpolated tick values (CLOSE_15m_tick_1-8, CLOSE_30m_tick_1-8) + 3 seasonal features calculated deterministically from 23 base features
    *   **Sub-Periodicity Generation**: 15-min and 30-min tick values interpolated from hourly CLOSE prices with realistic temporal noise
    *   **Final Output**: 23 base + 15 technical + 16 ticks + 3 seasonal = 57 total features
*   **Operational Modes**: Supports three distinct operational modes, each managed by dedicated pipeline modules:
    *   **Train Mode**: Trains GAN components using 23-feature architecture only
    *   **Generate Mode**: Generates 23-feature synthetic data, then post-processes to 44 features
    *   **Optimize Mode**: For hyperparameter tuning and model optimization
*   **Pre-trained Model Integration**: Leverages pre-trained VAE decoder outputting 23 base features, which serves as the core component of the generator.
*   **Improved Training Efficiency**: Smaller networks (23 vs 51+ features) with better authenticity, faster training, and eliminated feature expansion complexity.
*   **Modular Plugin Architecture**: Allows for easy extension and customization through plugins for data feeding, generation, evaluation, and optimization.

## 2. Core Architecture: Sequential Conditional VAE-GAN (SC-VAE-GAN)

The SC-VAE-GAN architecture is central to the SDG system. It sequentially combines a Variational Autoencoder (VAE) and a Generative Adversarial Network (GAN), with conditioning mechanisms to ensure temporal coherence and relevance.

### 2.1. Architectural Components

1.  **Pre-trained VAE Decoder (3-Input)**:
    *   A key component of the GAN's generator. This decoder is pre-trained and loaded into the system.
    *   Crucially, this VAE decoder is designed to accept **three distinct inputs** when integrated into the composite GAN generator:
        1.  `decoder_input_z_seq`: Latent space sequences, typically of shape `(batch_size, 18, 32)`. These are internally generated by a BiLSTM Z-generator within the composite GAN generator, transforming an initial noise vector.
        2.  `decoder_input_conditions`: Conditional features vector, typically of shape `(batch_size, 10)`. This input provides conditioning information based on cyclical date/time features for the *current* timestep.
        3.  `decoder_input_context` (Implied for Sequential Generation): For generating sequences step-by-step, the decoder (or the composite generator it's part of) implicitly uses context from the previously generated timestep. This is essential for maintaining temporal dependencies in the output sequence. The exact mechanism (e.g., passing the previous output as an explicit input or managing hidden states in recurrent layers) is part of the composite generator's design.
    *   The decoder's primary output (e.g., from its `reconstruction_out` layer) is a set of base features (e.g., 23 features of shape `(batch_size, 23)`).

2.  **Composite GAN Generator**:
    *   This is not just the VAE decoder but a larger Keras model that *includes* the VAE decoder.
    *   **Internal BiLSTM Z-Generator**: Transforms initial noise into the latent sequences (`decoder_input_z_seq`) required by the VAE decoder. Example architecture: Dense(576) → Reshape(18,32) → Bidirectional(LSTM(64)) → Conv1D(32 filters).
    *   **Conditioning Integration**: Manages the preparation and input of conditional features (`decoder_input_conditions`) to the VAE decoder.
    *   **Sequential Generation Logic**: Implements the iterative process of generating time series data, using the output of the previous timestep to inform the generation of the current timestep (context).
    *   **Post-processing - Technical Indicators & Feature Assembly**:
        *   Takes the base features output by the VAE decoder.
        *   Calculates the 20 technical indicators using these base features (e.g., OHLC).
        *   Combines the VAE output, calculated technical indicators, and cyclical date/time features (seasonal variables) to produce the final 51-feature output sequence. The expected output shape per step, when assembled, is `(batch_size, sequence_length, 51)`.

3.  **Conditional Generation**:
    *   **Date/Time Features (Seasonal Variables)**: Cyclical representations of time (e.g., `hour_of_day_sin`, `day_of_week_cos`) are used as conditional inputs to guide the generation process, ensuring the synthetic data reflects temporal patterns. These are part of the `decoder_input_conditions` and also included in the final 51-feature output.
    *   **Previous Timestep Context**: The output of the previous synthetic timestep is used to condition the generation of the current timestep, ensuring temporal continuity. This is managed by the Composite GAN Generator.

4.  **Generative Adversarial Network (GAN)**:
    *   The Composite GAN Generator (G) and a Discriminator (D) are trained adversarially.
    *   The Discriminator is designed to distinguish between real time series data (processed to have 51 features) and synthetic data from the Generator. It typically uses a Conv1D/LSTM architecture.
    *   The training process aims to improve the Generator's ability to produce realistic data that the Discriminator cannot easily identify as fake.

### 2.2. Data Flow and Feature Engineering

*   **Input**: The generation process starts with an initial noise vector and a sequence of date/time information for conditioning.
*   **Feeder Plugin**: Prepares the initial noise, date/time conditions, and potentially initial context for the generator.
*   **Generator Process (23-Feature Training Architecture)**:
    1.  The internal BiLSTM Z-generator creates latent sequences from noise.
    2.  The VAE decoder takes these latent sequences and current timestep conditions to produce 23 base features:
        *   OHLC (Open, High, Low, Close) prices
        *   Market indicators (VIX close, S&P500 close)
        *   Bid/Ask spreads (BC-BO, BH-BL)
        *   Sub-periodicity ticks (CLOSE_15m_tick_1-8, CLOSE_30m_tick_1-8)
    3.  **Training Mode**: Generator outputs these 23 base features directly to discriminator for adversarial training.
    4.  **Generate Mode**: After generation, post-processing expands 23 features to 44 features.
    5.  This process is repeated iteratively to form a sequence, using the previous step's output as context.
*   **Post-Processing Pipeline (Generate Mode Only)**:
    1.  Technical indicators (15 features: RSI, MACD, EMA, Bollinger Bands, etc.) calculated from 23 base features.
    2.  Seasonal features (3 features: cyclical encodings) generated from timestamps.
    3.  Features expanded from 23 → 44 total features when needed for downstream tasks.
*   **Output**: 
    *   **Training Mode**: Synthetic time series with 23 base features per timestep. Shape: `(batch_size, sequence_length, 23)`
    *   **Generate Mode**: Post-processed synthetic time series with 44 features per timestep. Shape: `(batch_size, sequence_length, 44)`

### 2.3. Training Process Specifics

*   **Pre-trained VAE Decoder**: The VAE decoder component within the Composite GAN Generator is loaded with pre-trained weights but is set to `trainable=True` during GAN training, allowing for fine-tuning in the context of the adversarial setup.
*   **Feature Consistency**: A critical step (`prepare_features_for_discriminator` method in `GeneratorPlugin`) ensures that real data fed to the discriminator is processed to match the 23-feature format:
    1.  **Base Feature Extraction**: Extracts the first 23 base features from real data.
    2.  **Feature Padding**: If input data has fewer than 23 features, it pads with zeros.
    3.  **Consistent Ordering**: Ensures processed real data maintains the same feature order as generator output.
    This guarantees the discriminator receives input with shape `(batch_size, sequence_length, 23)` for stable adversarial training.
*   **Regularization**: Specific L2 regularization is applied to the generator, while the discriminator generally avoids explicit regularization to maintain a balance in training.
*   **Learning Rate Scheduling**: `ReduceLROnPlateau` is used for dynamic learning rate adjustment for both generator and discriminator.
    *   Callbacks are configured in `GANTrainerPlugin` and monitor `g_loss` and `d_loss`.
    *   `TrainingCoordinator` calls their `on_epoch_end` method after each epoch.
*   **Early Stopping**:
    *   Parameters for early stopping are configured in `GANTrainerPlugin` (e.g., `enable_early_stopping`, `es_patience`, `es_min_delta`, `es_monitor_metric`).
    *   The `EarlyStopping` callback is initialized in `GANTrainerPlugin`.
    *   The `TrainingCoordinator` calls `early_stopping_callback.on_train_begin()` and `early_stopping_callback.on_epoch_end()` appropriately.
    *   If `early_stopping_callback.model.stop_training` becomes `True`, the training loop is terminated, and final models are saved.
*   **Model Saving**:
    *   The `TrainingCoordinator` saves the generator and discriminator models.
    *   If training completes all epochs or is stopped early, the final models are saved using filenames specified in `app/config.py`: `save_generator_sequential_model_file` and `save_discriminator_sequential_model_file`. These are saved in the directory constructed from `results_base_dir` and `save_model_dir`.
    *   The composite GAN model (generator + non-trainable discriminator used for generator training) is not explicitly saved with a final name by default, but intermediate epoch-based saves would include it if enabled.

## 3. Operational Modes Detailed

### 3.1. Train Mode

*   **Purpose**: To train the GAN, specifically improving the Composite GAN Generator and the Discriminator through adversarial learning using the 23-feature base architecture.
*   **Core Process**:
    1.  Load real training and validation data.
    2.  Load the pre-trained VAE decoder (specified by `config["generator_vae_decoder_model_path_param"]`) into the `GeneratorPlugin`. The VAE decoder is set to `trainable=True` for fine-tuning.
    3.  The `GeneratorPlugin` builds the composite GAN generator, which includes the VAE decoder and an internal BiLSTM Z-generator.
    4.  The `DiscriminatorPlugin` builds the discriminator model expecting 23-feature inputs.
    5.  The `GANTrainerPlugin` orchestrates the training via `TrainingCoordinator`:
        *   Generator outputs 23 base features directly to discriminator.
        *   Real data is processed to match the 23-feature format for discriminator training.
        *   Iterative adversarial training with improved efficiency due to smaller feature space.
        *   Detailed per-epoch logging (losses, learning rates, timing, `ReduceLROnPlateau` info).
        *   Dynamic learning rate adjustment using `ReduceLROnPlateau`.
        *   Early stopping based on configured metric and patience.
    6.  Save trained models. The final generator (full composite GAN generator outputting 23 features) and discriminator models are saved to paths specified by `config["save_generator_sequential_model_file"]` and `config["save_discriminator_sequential_model_file"]` respectively, within the `models_dir`.
*   **Key Inputs**: Real training data, pre-trained VAE decoder model file (via `config["generator_vae_decoder_model_path_param"]`).
*   **Key Outputs**: Improved/trained Composite GAN Generator model (23-feature output), trained Discriminator model (23-feature input), training logs, and loss metrics.

### 3.2. Generate Mode

*   **Purpose**: To produce synthetic time series data using a trained Composite GAN Generator outputting 23 base features.
*   **Core Process**:
    1.  Load the trained Composite GAN Generator model (which includes the fine-tuned VAE decoder and the BiLSTM Z-generator).
    2.  Initialize the Feeder plugin to provide initial noise, sequences of date/time conditions, and any required initial context.
    3.  Iteratively generate synthetic data points:
        *   The Composite GAN Generator takes noise, current conditions (and previous context).
        *   The internal BiLSTM Z-generator produces latent sequences.
        *   The VAE decoder part generates 23 base features.
        *   **Optional Post-Processing**: Technical indicators and datetime features calculated from the 23 base features when full feature sets are needed.
    4.  Export the generated data:
        *   **Core Output**: 23-feature time series data
        *   **Expanded Output**: Post-processed data with technical indicators and datetime features (when required)
*   **Key Inputs**: Trained Composite GAN Generator model file, parameters for generation (e.g., number of samples, start date for conditions).
*   **Key Outputs**: CSV file containing the synthetic time series data (23 base features, or expanded feature sets with post-processing).

### 3.3. Optimize Mode

*   **Purpose**: To find the optimal set of hyperparameters for the GAN training process or model architectures.
*   **Core Process**: (This section would be further detailed based on the specific implementation of the `OptimizerPlugin`)
    1.  Define a hyperparameter search space.
    2.  Iteratively select hyperparameter sets.
    3.  For each set, run the Train Mode for a defined number of epochs or until a convergence criterion is met.
    4.  Evaluate the performance of the generator trained with these hyperparameters (e.g., using an `EvaluatorPlugin`).
    5.  Use an optimization algorithm (e.g., Bayesian optimization, genetic algorithms) to select the next set of hyperparameters based on past results.
    6.  Report the best hyperparameter set found.
*   **Key Inputs**: Real training/validation data, pre-trained VAE decoder, hyperparameter search space definition.
*   **Key Outputs**: Optimal hyperparameter configuration, logs of the optimization process.

## Key Functionalities

### Generate Mode: Synthetic Data Generation and Prepending

**Overview**:
The "Generate Mode" is designed to produce synthetic time series data using pre-trained GAN models and prepend this data to an existing dataset. This is useful for augmenting datasets, creating historical data where none exists, or for specific simulation purposes. The core idea is to generate data that is chronologically earlier than the provided real data, seamlessly extending the dataset backwards in time, while ensuring that the generated timestamps fall only on weekdays.

**Activation and Prerequisites**:
*   `operation_mode` in `app/config.py` must be set to `"generate"`.
*   Valid file paths for pre-trained full Generator and Discriminator Keras models must be provided via `load_generator_sequential_model_file` and `load_discriminator_sequential_model_file` respectively.
*   `x_train_file` must point to the base real dataset.
*   `n_samples` specifies the number of synthetic samples to generate.
*   `dataset_periodicity` (e.g., "1h", "15min") is crucial for calculating time steps.

**Process Flow**:

1.  **Configuration Loading (`app/config_loader.py`)**:
    *   The main configuration is loaded, including `operation_mode`, model paths, `x_train_file`, `n_samples`, `max_steps_train`, `dataset_periodicity`, and `generated_data_file`.

2.  **Model Loading (e.g., in `app/main.py` or a dedicated generation module)**:
    *   The full Generator and Discriminator models are loaded from the `.keras` files specified in the configuration. This uses standard Keras model loading functions.
    *   `main.py` would orchestrate this based on `operation_mode == "generate"`.

3.  **Base Data Loading and Preparation (`app/data_processor.py` or similar)**:
    *   The `FeederPlugin` (or its underlying data loading capabilities) reads the initial segment of data from `x_train_file`. Only the first `max_steps_train` rows are loaded if the file is longer.
    *   The `DATE_TIME` column of this loaded data is parsed.
The first `DATE_TIME` entry from this segment becomes the reference point for generating earlier data.

4.  **Synthetic Data Generation Loop (Orchestrated by `app/main.py`, potentially using `GeneratorPlugin` and `FeederPlugin` utilities)**:
    *   **Target `DATE_TIME` Calculation**: The `DATE_TIME` of the first record from the loaded `x_train_file` segment is taken. Let this be `T_real_start`.
    *   A loop runs `n_samples` times to generate each synthetic sample:
        *   **Prospective `DATE_TIME` Calculation**: For the *k*-th synthetic sample (in reverse chronological order, so the first one generated is the one closest to `T_real_start`), its `DATE_TIME` (`T_synth_k`) is calculated by stepping back from `T_real_start` using `dataset_periodicity`. The very last synthetic sample generated (i.e., the `n_samples`-th one, which will be the earliest in the final dataset) will have its `DATE_TIME` calculated, and then subsequent synthetic samples will step forward towards `T_real_start`.
        Alternatively, and more straightforwardly for prepending: calculate the `DATE_TIME` for the *last* synthetic sample to be generated (which will be the one immediately preceding `T_real_start`). This is `T_real_start - 1 * dataset_periodicity`. Then, for each of the `n_samples` to generate (iterating from `i = 0` to `n_samples - 1`), the target `DATE_TIME` for the *i*-th sample (when ordered from earliest to latest) would be `(T_real_start - (n_samples - i) * dataset_periodicity)`.
        *   **Weekend Skipping**: The calculated `T_synth_k` is checked. If it falls on a Saturday or Sunday, it is skipped. The `DATE_TIME` is then adjusted to the preceding Friday. This means that the number of *actual* time steps (periods) skipped to find a valid weekday might be more than one `dataset_periodicity` unit. The generation process ensures `n_samples` *valid weekday* samples are created.
        *   **Conditional Input Preparation (Leveraging `FeederPlugin` logic)**: For the determined weekday `T_synth_k`:
            *   Cyclical features (hour of day, day of week, etc.) are derived from `T_synth_k`.
            *   A noise vector (latent vector) is generated, typically by sampling from a normal distribution (e.g., using `numpy.random.normal`). The dimensions of this vector must match the input shape expected by the loaded Generator model.
            *   These conditional inputs (cyclical features, noise) are combined into the format expected by the Generator.
        *   **Feature Generation (Using `GeneratorPlugin`'s model)**: The prepared input is fed to the loaded Generator model (`generator.predict(...)`). This outputs the 23 base features for `T_synth_k`.
        *   **Feature Assembly**: The synthetic sample is assembled:
            *   The 23 generated base features.
            *   The `DATE_TIME` (`T_synth_k`).
            *   **Optional Post-Processing**: Technical indicators and additional features calculated from the 23 base features when expanded feature sets are needed.
        *   The generated sample is stored.

5.  **Data Concatenation and Saving (`app/data_processor.py` or `app/main.py`)**:
    *   The list of `n_samples` generated synthetic records (which are already in correct chronological order, from earliest to latest, all on weekdays) is converted into a DataFrame.
    *   This DataFrame of synthetic data is concatenated with the DataFrame of the initially loaded segment from `x_train_file`. The synthetic data comes first.
    *   The combined DataFrame is saved to the `output_dir/generated_data_file` (e.g., as a CSV file).

**Interaction with Plugins**:
*   **`FeederPlugin`**: Its utilities for date parsing, cyclical feature generation, and potentially data loading will be heavily leveraged. The logic for generating `DATE_TIME` sequences, especially with weekend skipping and adherence to `dataset_periodicity`, might require extending or adapting `FeederPlugin`'s date handling capabilities or implementing new functions within `app/data_processor.py` that use `FeederPlugin`'s helpers.
*   **`GeneratorPlugin`**: While the plugin itself might not be directly instantiated in `generate` mode in the same way as in `train` mode (as it's tied to building models for training), the loaded Keras Generator *model* is central. The logic for preparing noise vectors and structuring inputs for the generator model will mirror what `GeneratorPlugin` does internally during training and prediction.
*   **`DiscriminatorPlugin`**: The loaded Discriminator model is available but not actively used in the basic generation loop described. It could be used for optional validation of generated samples if desired.

**Key Outputs**:
*   A single data file (e.g., CSV) located at `output_dir/generated_data_file`, containing the `n_samples` of synthetic data followed by the initial `max_steps_train` rows from `x_train_file`.
    *   **Core Format**: 23 base features + DATE_TIME column
    *   **Extended Format**: Post-processed with technical indicators and datetime features when required
*   Log messages indicating the start and completion of the generation process, number of samples generated, and the path to the output file.

---
*This document outlines the core functionality. For specific configuration details, file structures, and API definitions, please refer to `REFERENCE_Config_FileTree.md` and `REFERENCE_API.md`.*
